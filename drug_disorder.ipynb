{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c68781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca262b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = r\"D:\\rohini\\drug\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04b56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['addicted','not addicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c0eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef45b8b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting.... addicted\n",
      "extracting.... not addicted\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for i in classes:\n",
    "#     print(i)\n",
    "    img_arr = os.path.join(directory,i)\n",
    "#     print(img_arr)\n",
    "    for j in os.listdir(img_arr):\n",
    "#         print(len(os.listdir(img_arr)))\n",
    "#         print(j)\n",
    "        img_path = os.path.join(img_arr,j)\n",
    "#         print(img_path)\n",
    "        img_array = cv2.imread(img_path)\n",
    "        img_resize = cv2.resize(img_array,(224,224))\n",
    "        img_resize = img_resize/255\n",
    "        img_reshape = img_resize.reshape(224,224,3,1)\n",
    "        data.append(img_reshape)\n",
    "        labels.append(i)\n",
    "    print('extracting....',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9939cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0.75294118],\n",
       "          [0.52156863],\n",
       "          [0.24705882]],\n",
       "\n",
       "         [[0.76078431],\n",
       "          [0.5254902 ],\n",
       "          [0.25490196]],\n",
       "\n",
       "         [[0.77254902],\n",
       "          [0.53333333],\n",
       "          [0.26666667]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.43921569],\n",
       "          [0.46666667],\n",
       "          [0.44705882]],\n",
       "\n",
       "         [[0.43921569],\n",
       "          [0.46666667],\n",
       "          [0.44705882]],\n",
       "\n",
       "         [[0.43921569],\n",
       "          [0.46666667],\n",
       "          [0.44705882]]],\n",
       "\n",
       "\n",
       "        [[[0.73333333],\n",
       "          [0.50588235],\n",
       "          [0.24705882]],\n",
       "\n",
       "         [[0.74117647],\n",
       "          [0.51764706],\n",
       "          [0.25882353]],\n",
       "\n",
       "         [[0.76078431],\n",
       "          [0.53333333],\n",
       "          [0.28235294]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.44313725],\n",
       "          [0.47058824],\n",
       "          [0.45098039]],\n",
       "\n",
       "         [[0.44313725],\n",
       "          [0.47058824],\n",
       "          [0.45098039]],\n",
       "\n",
       "         [[0.44313725],\n",
       "          [0.47058824],\n",
       "          [0.45098039]]],\n",
       "\n",
       "\n",
       "        [[[0.71764706],\n",
       "          [0.49803922],\n",
       "          [0.27058824]],\n",
       "\n",
       "         [[0.71372549],\n",
       "          [0.49803922],\n",
       "          [0.27058824]],\n",
       "\n",
       "         [[0.70588235],\n",
       "          [0.49803922],\n",
       "          [0.2745098 ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.44705882],\n",
       "          [0.47843137],\n",
       "          [0.45098039]],\n",
       "\n",
       "         [[0.44705882],\n",
       "          [0.47843137],\n",
       "          [0.45098039]],\n",
       "\n",
       "         [[0.44705882],\n",
       "          [0.47843137],\n",
       "          [0.45098039]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.22745098],\n",
       "          [0.25882353],\n",
       "          [0.21960784]],\n",
       "\n",
       "         [[0.24313725],\n",
       "          [0.2745098 ],\n",
       "          [0.23529412]],\n",
       "\n",
       "         [[0.27058824],\n",
       "          [0.30196078],\n",
       "          [0.2627451 ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.19215686],\n",
       "          [0.26666667],\n",
       "          [0.34901961]],\n",
       "\n",
       "         [[0.19215686],\n",
       "          [0.26666667],\n",
       "          [0.34901961]],\n",
       "\n",
       "         [[0.19215686],\n",
       "          [0.26666667],\n",
       "          [0.34901961]]],\n",
       "\n",
       "\n",
       "        [[[0.22745098],\n",
       "          [0.25882353],\n",
       "          [0.21960784]],\n",
       "\n",
       "         [[0.24313725],\n",
       "          [0.2745098 ],\n",
       "          [0.23529412]],\n",
       "\n",
       "         [[0.27058824],\n",
       "          [0.30196078],\n",
       "          [0.2627451 ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.18431373],\n",
       "          [0.25882353],\n",
       "          [0.34117647]],\n",
       "\n",
       "         [[0.18823529],\n",
       "          [0.2627451 ],\n",
       "          [0.34509804]],\n",
       "\n",
       "         [[0.18823529],\n",
       "          [0.2627451 ],\n",
       "          [0.34509804]]],\n",
       "\n",
       "\n",
       "        [[[0.20784314],\n",
       "          [0.23921569],\n",
       "          [0.21176471]],\n",
       "\n",
       "         [[0.22745098],\n",
       "          [0.25882353],\n",
       "          [0.23137255]],\n",
       "\n",
       "         [[0.2627451 ],\n",
       "          [0.29411765],\n",
       "          [0.2627451 ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.20784314],\n",
       "          [0.29019608],\n",
       "          [0.37254902]],\n",
       "\n",
       "         [[0.21568627],\n",
       "          [0.29803922],\n",
       "          [0.38039216]],\n",
       "\n",
       "         [[0.22352941],\n",
       "          [0.30588235],\n",
       "          [0.38823529]]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(data)\n",
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d771ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 224, 224, 3, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42deecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7fd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1067ea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f4e8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "572f16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "828497fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 225)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1419e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 57)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51da7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv3D,MaxPool3D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff129986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(filters=(40),kernel_size=(3,3,3),input_shape=(224,224,3,1),padding='same'))\n",
    "model.add(MaxPool3D(pool_size=(3,3,1)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Conv3D(filters=(45),kernel_size=(3,3,3),activation=\"relu\"))\n",
    "model.add(MaxPool3D(pool_size=(3,3,1)))\n",
    "# model.add(Conv3D(filters=(50),kernel_size=(3,3,3),activation=\"sigmoid\"))\n",
    "# model.add(MaxPool3D(pool_size=(3,3,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "# model.add(Dense(7,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44118832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 224, 224, 3, 40)   1120      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 74, 74, 3, 40)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 74, 74, 3, 40)     0         \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 72, 72, 1, 45)     48645     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 24, 24, 1, 45)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25920)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               2592100   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,641,966\n",
      "Trainable params: 2,641,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1158334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=BinaryCrossentropy(),optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e446e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 77s 8s/step - loss: 0.9131 - accuracy: 0.4844 - val_loss: 0.6930 - val_accuracy: 0.5789\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 70s 8s/step - loss: 0.6930 - accuracy: 0.5600 - val_loss: 0.6936 - val_accuracy: 0.4912\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 70s 8s/step - loss: 0.6907 - accuracy: 0.5156 - val_loss: 0.6932 - val_accuracy: 0.5789\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 76s 8s/step - loss: 0.6782 - accuracy: 0.5911 - val_loss: 0.6878 - val_accuracy: 0.5789\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 80s 9s/step - loss: 0.6209 - accuracy: 0.6978 - val_loss: 0.6752 - val_accuracy: 0.5789\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.6978"
     ]
    }
   ],
   "source": [
    "h = model.fit(x_train,y_train,batch_size=25,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(x_test)\n",
    "pr = []\n",
    "for i in ypred:\n",
    "    if i >0.5:\n",
    "        j = 1\n",
    "        pr.append(j)\n",
    "    else:\n",
    "        j = 0\n",
    "        pr.append(j)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1e641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7addeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_accuracy=h.history['accuracy']\n",
    "val_accuracy=h.history['val_accuracy']\n",
    "train_loss=h.history['loss']\n",
    "test_loss=h.history['val_loss']\n",
    "epoch=h.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch,train_accuracy,label=\"train_accuracy\")\n",
    "plt.plot(epoch,val_accuracy,label=\"val_accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dd6b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch,train_loss,label=\"train loss\")\n",
    "plt.plot(epoch,test_loss,label=\"test loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09536edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372de63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image.open(r\"D:\\rohini\\drug\\addicted\\95.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"D:\\rohini\\drug\\addicted\\95.jpg\")\n",
    "img_resize=cv2.resize(img,(224,224))\n",
    "img_resize=img_resize/255\n",
    "img_reshaped=img_resize.reshape(224,224,3,1)\n",
    "test=[]\n",
    "test.append(img_reshaped)\n",
    "test=np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result>0.5:\n",
    "    print(\"Not Addicted\")\n",
    "else:\n",
    "    print(\"Addicted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dr_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62246d",
   "metadata": {},
   "source": [
    "# Second Model- VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    vgg= VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "    vgg.layers\n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable= False\n",
    "    x= layers.Flatten()(vgg.output) #A flatten operation on a tensor reshapes the tensor to have the shape that is equal to the number of elements contained in tensor non including the batch dimension.\n",
    "    x= layers.Dropout(0.25)(x) #Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly.\n",
    "    x= layers.Dense(1024, activation='relu')(x)\n",
    "    #Dense layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the operation on the input and return the output.\n",
    "    x= layers.Dropout(0.15)(x)\n",
    "    out= layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs= vgg.input, outputs=out)\n",
    "\n",
    "model1= build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ff28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss= tensorflow.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(0.0002), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85617a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop= tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                                      mode='min', verbose=1, patience=4)\n",
    "\n",
    "# check= tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "#     './model22_wg.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "#     save_weights_only=True, mode='min', save_freq='epoch')\n",
    "his = model1.fit(x_train,y_train,batch_size=500,epochs=10,validation_data=(x_test,y_test))\n",
    "# his= model.fit(x_train,y_train,\n",
    "#                         validation_data=(x_test,y_test),\n",
    "#                         epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ff0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1, figsize = (20, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot( his.history[\"loss\"], label = \"Training Loss\")\n",
    "plt.plot( his.history[\"val_loss\"], label = \"Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot( his.history[\"accuracy\"], label = \"Training Accuracy\")\n",
    "plt.plot( his.history[\"val_accuracy\"], label = \"Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c061541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e39e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(r\"D:\\rohini\\drug\\addicted\\a75.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c564ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"D:\\rohini\\drug\\addicted\\a75.jpg\")\n",
    "img_resize=cv2.resize(img,(224,224))\n",
    "img_resize=img_resize/255\n",
    "img_reshaped=img_resize.reshape(224,224,3,1)\n",
    "test=[]\n",
    "test.append(img_reshaped)\n",
    "test=np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model1.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ba88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bf6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71402c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d57b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a114822",
   "metadata": {},
   "source": [
    "# Third model- DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = r\"D:\\rohini\\drug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61897b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['addicted','not addicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4856aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddcc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for i in classes:\n",
    "#     print(i)\n",
    "    img_arr = os.path.join(directory,i)\n",
    "#     print(img_arr)\n",
    "    for j in os.listdir(img_arr):\n",
    "#         print(len(os.listdir(img_arr)))\n",
    "#         print(j)\n",
    "        img_path = os.path.join(img_arr,j)\n",
    "#         print(img_path)\n",
    "        img_array = cv2.imread(img_path)\n",
    "        img_resize = cv2.resize(img_array,(256,256))\n",
    "        img_resize = img_resize/255\n",
    "        img_reshape = img_resize.reshape(256,256,3)\n",
    "        data.append(img_reshape)\n",
    "        labels.append(i)\n",
    "    print('extracting....',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data)\n",
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e906cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # First block\n",
    "# model.add(Conv2D(32, (3, 3), padding='same', input_shape=(64,64,3), kernel_regularizer=l2(1E-4)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(1E-4)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(1E-4)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (1, 1), padding='same', kernel_regularizer=l2(1E-4)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# # Dense block\n",
    "# model.add(Dense(256, kernel_regularizer=l2(1E-4)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# # Output layer\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f75ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.15))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(50))\n",
    "# model.add(Dense(1, activation=tensorflow.nn.sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2dbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bf7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (282,256)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a 1D convolutional layer with 64 filters, a kernel size of 3 and ReLU activation\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add batch normalization and max pooling\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "# Add another convolutional layer with 128 filters and a kernel size of 3\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "\n",
    "# Add batch normalization and max pooling\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "# Add a third convolutional layer with 256 filters and a kernel size of 3\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "\n",
    "# Add batch normalization and max pooling\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer with 512 units and ReLU activation\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add a final output layer with a sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24625644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48eb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv3D,MaxPool3D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy,BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e767be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=BinaryCrossentropy(),optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(x_train,y_train,batch_size=25,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_accuracy=h.history['accuracy']\n",
    "val_accuracy=h.history['val_accuracy']\n",
    "train_loss=h.history['loss']\n",
    "test_loss=h.history['val_loss']\n",
    "epoch=h.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch,train_accuracy,label=\"train_accuracy\")\n",
    "plt.plot(epoch,val_accuracy,label=\"val_accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch,train_loss,label=\"train loss\")\n",
    "plt.plot(epoch,test_loss,label=\"test loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = []\n",
    "y_pred = model.predict(x_test)\n",
    "for i in y_pred:\n",
    "    pr.append(np.argmax(i))\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d610a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(r\"D:\\rohini\\drug\\not addicted\\135.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"D:\\rohini\\drug\\not addicted\\135.jpg\")\n",
    "img_resize=cv2.resize(img,(64,64))\n",
    "img_resize=img_resize/255\n",
    "img_reshaped=img_resize.reshape(64,64,3,1)\n",
    "test=[]\n",
    "test.append(img_reshaped)\n",
    "test=np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9496bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_test,pred)*100\n",
    "print(\"Accuracy:\",acc_score)\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "print('confussion metrics is :',cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
